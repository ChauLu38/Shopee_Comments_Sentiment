# -*- coding: utf-8 -*-
"""Shopee_Sentiments_Step3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UAxgsp5Rig18OYVbiLZhWODPlD7xKsWx
"""

# from google.colab import drive
# drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# % cd '/content/gdrive/MyDrive/Study/Capstone_Project_LuHongChau'

###**1. EDA**

# Commented out IPython magic to ensure Python compatibility.
# import random
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('tkagg')
# import lazypredict
# %matplotlib inline

data = pd.read_excel('shopee_fashion_comments.xlsx')

# data.head()

# data.shape

data_sub=data[['content','rating']]

# xóa dữ liệu ẩn
hide_str='****** Đánh giá đã bị ẩn do nội dung không phù hợp. ******'
data_sub = data_sub[data_sub.content != hide_str]

# data_sub.shape

# kiểm tra dữ liệu na/null
# data_sub.isna().sum()

# xóa dữ liệu na/null
data_sub = data_sub.dropna(axis=0, subset=['content'])

# data_sub.shape

# xóa dữ liệu trùng
data_sub = data_sub.drop_duplicates()

# data_sub.shape

data_sub['content'].str.len().hist()
plt.title("Number of letters of each comment")
# plt.show()

# """- Mỗi comment có từ 1 đến 300 ký tự. Trong đó phổ biến từ 60 - 90 ký tự vì Shopee quy định mỗi comment có độ dài từ 50 ký tự mới được nhận thưởng xu."""

data_sub['content'].str.split().map(lambda x: len(x)).hist()
plt.title("Number of words of each comment")
# plt.show()

# """- Mỗi comment có từ 1 đến gần 80 từ với khoảng từ 10-20 từ là số từ phổ biến nhất"""

data_sub['content'].str.split().\
   apply(lambda x : [len(i) for i in x]). \
   map(lambda x: np.mean(x)).hist()
plt.title("Number of letters of each word")
# plt.show()

# """- Mỗi từ có từ 1 đến hơn 15 ký tự. Tuy nhiên, từ tiếng Việt dài nhất có 7 ký tự => có các từ sai chính tả, hoặc bổ sung có ký tự không cần thiết để đủ nhận thưởng xu"""

plt.figure(figsize=(8, 6))
sns.countplot(x='rating', data=data_sub)
plt.xlabel("Rating")
plt.title("Number of data of each rating")
# plt.show()

# """- Lượng đánh giá 5 sao chiếm nhiều nhất do các gian bán hàng trên trang shopee có thuê người comment để tăng chỉ số.

# ###**2. Preprocessing**
# """

# !pip install underthesea --quiet
# !pip install demoji --quiet
# !pip install pyvi --quiet
# !pip install --upgrade scikit-learn --quiet

from underthesea import word_tokenize, pos_tag, sent_tokenize
import regex
import demoji
from pyvi import ViPosTagger, ViTokenizer
import string
import wordcloud

data_sub.info()

data_sub['content'] = data_sub['content'].astype(str)

data_sub.head()

##LOAD EMOJICON
file = open('files/emojicon.txt', 'r', encoding="utf8")
emoji_lst = file.read().split('\n')
emoji_dict = {}
for line in emoji_lst:
    key, value = line.split('\t')
    emoji_dict[key] = str(value)
file.close()
#################
#LOAD TEENCODE
file = open('files/teencode.txt', 'r', encoding="utf8")
teen_lst = file.read().split('\n')
teen_dict = {}
for line in teen_lst:
    key, value = line.split('\t')
    teen_dict[key] = str(value)
file.close()
###############
#LOAD TRANSLATE ENGLISH -> VNMESE
file = open('files/english-vnmese.txt', 'r', encoding="utf8")
english_lst = file.read().split('\n')
english_dict = {}
for line in english_lst:
    key, value = line.split('\t')
    english_dict[key] = str(value)
file.close()
################
#LOAD wrong words
file = open('files/wrong-word.txt', 'r', encoding="utf8")
wrong_lst = file.read().split('\n')
file.close()
#################
#LOAD STOPWORDS
file = open('files/vietnamese-stopwords.txt', 'r', encoding="utf8")
stopwords_lst = file.read().split('\n')
file.close()
#LOAD NOTWORDS
file = open('files/not.txt', 'r', encoding="utf8")
not_lst = file.read().split('\n')
file.close()

def process_text(text, emoji_dict, teen_dict, wrong_lst):
    document = text.lower()
    document = document.replace("’",'')
    document = regex.sub(r'\.+', ".", document)
    new_sentence =''
    for sentence in sent_tokenize(document):
        # if not(sentence.isascii()):
        ###### CONVERT EMOJICON
        sentence = ''.join(' '+emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))
        ###### DEL Punctuation & Numbers
        pattern = r'(?i)\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\b'
        sentence = ' '.join(regex.findall(pattern,sentence))
        ###### CONVERT TEENCODE
        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())
        ###### DEL wrong words   
        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())
        new_sentence = new_sentence+ sentence + '. '                    
    document = new_sentence  
    #print(document)
    ###### DEL excess blank space
    document = regex.sub(r'\s+', ' ', document).strip()
    document = regex.sub(r'([a-z])\1+', lambda m: m.group(1).lower(), document, flags=regex.IGNORECASE)
    return document

# Chuẩn hóa unicode tiếng việt
def loaddicchar():
    uniChars = "àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ"
    unsignChars = "aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU"

    dic = {}
    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(
        '|')
    charutf8 = "à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ".split(
        '|')
    for i in range(len(char1252)):
        dic[char1252[i]] = charutf8[i]
    return dic
 
# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại
def covert_unicode(txt):
    dicchar = loaddicchar()
    return regex.sub(
        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',
        lambda x: dicchar[x.group()], txt)

def process_special_word(text):
    for khong in not_lst:
      new_text = ''
      text_lst = text.split()
      i= 0
      if khong in text_lst:
          while i <= len(text_lst) - 1:
              word = text_lst[i]
              if  word == khong:
                  next_idx = i+1
                  if next_idx <= len(text_lst) -1:
                      word = word +'_'+ text_lst[next_idx]
                  i= next_idx + 1
              else:
                  i = i+1
              new_text = new_text + word + ' '
      else:
          new_text = text
      text=new_text
    return new_text.strip()

def process_postag_thesea(text):
    new_document = ''
    for sentence in sent_tokenize(text):
        sentence = sentence.replace('.','')
        ###### POS tag
        lst_word_type = ['A','AB','V','VB','VY','R','M']
        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format="text"))))
        new_document = new_document + sentence + ' '
    ###### DEL excess blank space
    new_document = regex.sub(r'\s+', ' ', new_document).strip()
    return new_document

def remove_stopword(text, stopwords):
    ###### REMOVE stop words
    document = ' '.join('' if word in stopwords else word for word in text.split())
    ###### DEL excess blank space
    document = regex.sub(r'\s+', ' ', document).strip()
    return document

# df = pd.DataFrame()

# df['content'] = data_sub['content']
# df['rating'] = data_sub['rating']

# tx = [process_text(i , emoji_dict, teen_dict, wrong_lst) for i in data_sub['content']]

# tx = [covert_unicode(i) for i in tx]

# tx = [process_postag_thesea(i) for i in tx]

# tx = [remove_stopword(i, stopwords_lst) for i in tx]

# df['text'] = np.array(tx)

# """##**3. Visualize Data**"""

df = pd.read_excel("shopee_com_clean.xlsx")

df_sub=df[['text','rating']]

# Create label column
conditions = [
    (df_sub['rating'] <= 1),
    (df_sub['rating'] <= 4),
    (df_sub['rating'] >4)
    ]
values = ['negative', 'neutral', 'positive']
df_sub['label'] = np.select(conditions, values)

df_sub2=df_sub[['text', 'label','rating']]
df_sub2.head()

# df_sub2.shape

df_sub2['text'] = df_sub2['text'].replace('', np.nan)

# xóa dữ liệu na/null
df_sub2 = df_sub2.dropna(axis=0, subset=['text'])

# df_sub2.shape

# xóa dữ liệu trùng
df_sub2 = df_sub2.drop_duplicates()

# df_sub2.shape

# Tỷ lệ label
sns.countplot(x='label', data=df_sub2)
plt.xlabel("label")
plt.title("Number of data of each label")
# plt.show()

# """- Dữ liệu không cân bằng, tỷ lệ neutral chiếm chủ yếu"""

df_sub2.head(2)

def black_color_func(word, font_size, position,orientation,random_state=None, **kwargs):
    return("hsl(0,100%, 1%)")

# Positive
cloud = np.array(df_sub2[df_sub2['label']=='positive']['text']).flatten()
plt.figure(figsize=(10,8))
word_cloud = wordcloud.WordCloud(max_words=100,background_color ="white",
                               width=2000,height=1000).generate(str(cloud))                      
word_cloud.recolor(color_func = black_color_func)
plt.axis("off")
plt.imshow(word_cloud)
plt.title('Positive class',fontdict = {'fontsize' : 30, 'color':'blue'})
# plt.show()

# Neutral
cloud = np.array(df_sub2[df_sub2['label']=='neutral']['text']).flatten()
plt.figure(figsize=(10,8))
word_cloud = wordcloud.WordCloud(max_words=100,background_color ="white",
                               width=2000,height=1000).generate(str(cloud))                      
word_cloud.recolor(color_func = black_color_func)
plt.axis("off")
plt.title('Neutral class',fontdict = {'fontsize' : 30, 'color':'blue'})
plt.imshow(word_cloud)
# plt.show()

# negative
cloud = np.array(df_sub2[df_sub2['label']=='negative']['text']).flatten()
plt.figure(figsize=(10,8))
word_cloud = wordcloud.WordCloud(max_words=100,background_color ="white",
                               width=2000,height=1000).generate(str(cloud))                      
word_cloud.recolor(color_func = black_color_func)
plt.axis("off")
plt.title('Negative class',fontdict = {'fontsize' : 30, 'color':'blue'})
plt.imshow(word_cloud)
# plt.show()

# """##**4.Build model**"""

# from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
# from sklearn.svm import SVC
# from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix 
from sklearn.model_selection import train_test_split  
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn import metrics
import time
# thu vien Tokenizer Viet
from pyvi import ViTokenizer, ViPosTagger

# df_sub2.shape

y = df_sub2['label']
X = df_sub2['text']

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)

# X_train.shape

label_encoder = LabelEncoder()
label_encoder.fit(y_train)
# print(list(label_encoder.classes_), '\n')
y_train = label_encoder.transform(y_train)
y_test = label_encoder.transform(y_test)

# """####**Naive Bayes**"""

# start_time = time.time()

# pipe_line_nb = Pipeline([
#     ('vect', CountVectorizer()), #bag-of-words
#     ('tfidf', TfidfTransformer()), #tf-idf
#     ('clf', MultinomialNB()) #model naive bayes
# ])

# pipe_line_nb.fit(X_train, y_train)

# train_time_nb = time.time() - start_time
# print('Naive Bayes in', train_time_nb, 'seconds')

# pipe_line_nb.score(X_train, y_train)

# pipe_line_nb.score(X_test, y_test)

# y_testhat = pipe_line_nb.predict(X_test)

# # Xem kết quả thống kê
# print(confusion_matrix(y_test, y_testhat))
# print(classification_report(y_test,y_testhat))

# entries = []
# entries.append(['Naive Bayes', pipe_line_nb.score(X_train, y_train), 
#                     pipe_line_nb.score(X_test, y_test), abs(pipe_line_nb.score(X_train, y_train)-pipe_line_nb.score(X_test, y_test)), 
#                     train_time_nb])

# """####**Logistic Regression**"""

# start_time = time.time()
# pipe_line_lg = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),
#                                              max_df=0.8,
#                                              max_features=None)), 
#                      ('tfidf', TfidfTransformer()),
#                      ('clf', LogisticRegression(solver='lbfgs', 
#                                                 multi_class='auto',
#                                                 max_iter=10000))
#                     ])
# pipe_line_lg.fit(X_train, y_train)
 
# train_time_lg = time.time() - start_time
# print('Linear Classifier in', train_time_lg, 'seconds')

# pipe_line_lg.score(X_train, y_train)

# pipe_line_lg.score(X_test, y_test)

# y_testhat = pipe_line_lg.predict(X_test)

# # Xem kết quả thống kê
# print(confusion_matrix(y_test, y_testhat))
# print(classification_report(y_test,y_testhat))

# entries.append(['Logistic Regression', pipe_line_lg.score(X_train, y_train), 
#                     pipe_line_lg.score(X_test, y_test), abs(pipe_line_lg.score(X_train, y_train)-pipe_line_lg.score(X_test, y_test)), 
#                     train_time_lg])

# """####**SVM**"""

# start_time = time.time()
# pipe_line_sv = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),
#                                              max_df=0.8,
#                                              max_features=None)), 
#                      ('tfidf', TfidfTransformer()),
#                      ('clf', SVC(gamma='scale'))
#                     ])
# pipe_line_sv.fit(X_train, y_train)
 
# train_time_sv = time.time() - start_time
# print('SVM in', train_time_sv, 'seconds')

# pipe_line_sv.score(X_train, y_train)

# pipe_line_sv.score(X_test, y_test)

# y_testhat = pipe_line_sv.predict(X_test)

# # Xem kết quả thống kê
# print(confusion_matrix(y_test, y_testhat))
# print(classification_report(y_test,y_testhat))

# entries.append(['SVM', pipe_line_sv.score(X_train, y_train), 
#                     pipe_line_sv.score(X_test, y_test), abs(pipe_line_sv.score(X_train, y_train)-pipe_line_sv.score(X_test, y_test)), 
#                     train_time_sv])

# """####**Decision Tree**"""

# start_time = time.time()
# pipe_line_dt = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),
#                                              max_df=0.8,
#                                              max_features=None)), 
#                      ('tfidf', TfidfTransformer()),
#                      ('clf', DecisionTreeClassifier())
#                     ])
# pipe_line_dt.fit(X_train, y_train)
 
# train_time_dt = time.time() - start_time
# print('Decision Tree in', train_time_dt, 'seconds')

# pipe_line_dt.score(X_train, y_train)

# pipe_line_dt.score(X_test, y_test)

# y_testhat = pipe_line_dt.predict(X_test)

# # Xem kết quả thống kê
# print(confusion_matrix(y_test, y_testhat))
# print(classification_report(y_test,y_testhat))

# entries.append(['Decision Tree', pipe_line_dt.score(X_train, y_train), 
#                     pipe_line_dt.score(X_test, y_test), abs(pipe_line_dt.score(X_train, y_train)-pipe_line_dt.score(X_test, y_test)), 
#                     train_time_dt])

# """####**Random Forest**"""

# start_time = time.time()
# pipe_line_rf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),
#                                              max_df=0.8,
#                                              max_features=None)), 
#                      ('tfidf', TfidfTransformer()),
#                      ('clf', RandomForestClassifier(n_estimators=1000, random_state=0))
#                     ])
# pipe_line_rf.fit(X_train, y_train)
 
# train_time_rf = time.time() - start_time
# print('Random Forest in', train_time_rf, 'seconds')

# pipe_line_rf.score(X_train, y_train)

# pipe_line_rf.score(X_test, y_test)

# y_testhat = pipe_line_rf.predict(X_test)

# # Xem kết quả thống kê
# print(confusion_matrix(y_test, y_testhat))
# print(classification_report(y_test,y_testhat))

# entries.append(['Random Forest', pipe_line_rf.score(X_train, y_train), 
#                     pipe_line_rf.score(X_test, y_test), abs(pipe_line_rf.score(X_train, y_train)-pipe_line_rf.score(X_test, y_test)), 
#                     train_time_rf])

# """####**SGDClassifier**"""

start_time = time.time()
pipe_line_sg = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),
                                             max_df=0.8,
                                             max_features=None)), 
                     ('tfidf', TfidfTransformer()),
                     ('clf', SGDClassifier())
                    ])
pipe_line_sg.fit(X_train, y_train)
 
train_time_sg = time.time() - start_time
# print('SGDClassifier in', train_time_sg, 'seconds')

# print(' Score train:',pipe_line_sg.score(X_train, y_train))

# print('Score test:',pipe_line_sg.score(X_test, y_test))

y_testhat = pipe_line_sg.predict(X_test)

# Xem kết quả thống kê
conf_m = confusion_matrix(y_test, y_testhat)
class_re = classification_report(y_test,y_testhat)

entries=[]
entries.append(['SGDClassifier', pipe_line_sg.score(X_train, y_train), 
                    pipe_line_sg.score(X_test, y_test), abs(pipe_line_sg.score(X_train, y_train)-pipe_line_sg.score(X_test, y_test)), 
                    train_time_sg])

cv_df = pd.DataFrame(entries, 
                     columns=['model_name', 'score_train_mean', 
                              'score_test_mean', 'abs|score|', 'time_mean'])

# print(cv_df)

# plt.figure(figsize=(20, 4))
# plt.subplot(1, 4, 1)
# plt.bar(cv_df['model_name'],cv_df['score_train_mean'])
# plt.xlabel('model_name')
# plt.ylabel('Score train')
# plt.xticks(rotation='vertical')
# plt.title("Score train")

# plt.subplot(1, 4, 2)
# plt.bar(cv_df['model_name'],cv_df['score_test_mean'])
# plt.xlabel('model_name')
# plt.ylabel('Score test')
# plt.xticks(rotation='vertical')
# plt.title("Score test")

# plt.subplot(1, 4, 3)
# plt.bar(cv_df['model_name'],cv_df['abs|score|'])
# plt.xlabel('model_name')
# plt.ylabel('abs|score|')
# plt.xticks(rotation='vertical')
# plt.title("abs|score|")

# plt.subplot(1, 4, 4)
# plt.bar(cv_df['model_name'],cv_df['time_mean'])
# plt.xlabel('model_name')
# plt.ylabel('time_mean')
# plt.xticks(rotation='vertical')
# plt.title("time_mean")

# plt.show()

# """- Dựa vào bảng so sánh, ta thấy score train cao nhất ở Decision Tree và Random Forest nhưng 2 model này cũng có chênh lệch score train và score test nhiều nhất => không chọn 2 model này.
# - SVM có score test cao nhất, nhưng phần chênh lệch với các model khác là không nhiều ~1% và có thời gian train tương đối cao, gấp hơn 20 lần so với các model khác => không chọn SVM
# - Naive Bayes có thời gian train thấp nhất nhưng lại có score train và score test thấp => không chọn NB
# - Logistic Regression có score train và score test cao hơn SGDClassifier. Tuy nhiên phần chênh lệch giữa 2 chỉ số này của Logistic Regression là ~5% và có thời gian train dài gấp 15 lần so với SGDClassifier => Chọn SGDClassifier cho đề tài này.

# ##**5. ACTIVE_LEARNING**
# """

df_org = pd.read_excel('shopee_com_clean.xlsx')

# df_org.head()

df_labeled = pd.read_excel('labeled_data.xlsx')
# df_labeled.head()

# df_labeled.shape

df_org = df_org.dropna().drop_duplicates(subset='content')
df_org.head()

df_not_labeled = df_org[~df_org.content.isin(df_labeled.content.to_list())]
# df_not_labeled.shape

df_final = df_labeled.append(df_not_labeled[['content']])
df_final.head()

# df_final.shape

#Chuẩn hóa data:
# tx = [process_text(i , emoji_dict, teen_dict, wrong_lst) for i in df_final['content']]
# tx = [covert_unicode(i) for i in tx]
# tx = [process_postag_thesea(i) for i in tx]
# tx = [remove_stopword(i, stopwords_lst) for i in tx]
# df_final['content'] = tx

# print(df_final.shape)

# df_final.fillna(-1, inplace=True)
# df_final.tail()

from sklearn.preprocessing import FunctionTransformer
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.semi_supervised import LabelSpreading
from sklearn.metrics import f1_score
import os

# Parameters
sdg_params = dict(alpha=1e-5, penalty="l2", loss="log")
vectorizer_params = dict(ngram_range=(1, 2), min_df=5, max_df=0.8)
# Supervised Pipeline
pipeline = Pipeline(
    [
        ("vect", CountVectorizer(**vectorizer_params)),
        ("tfidf", TfidfTransformer()),
        ("clf", SGDClassifier(**sdg_params)),
    ]
)
# SelfTraining Pipeline
st_pipeline = Pipeline(
    [
        ("vect", CountVectorizer(**vectorizer_params)),
        ("tfidf", TfidfTransformer()),
        ("clf", SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True)),
    ]
)
# LabelSpreading Pipeline
ls_pipeline = Pipeline(
    [
        ("vect", CountVectorizer(**vectorizer_params)),
        ("tfidf", TfidfTransformer()),
        # LabelSpreading does not support dense matrices
        ("todense", FunctionTransformer(lambda x: x.todense())),
        ("clf", LabelSpreading()),
    ]
)

# Commented out IPython magic to ensure Python compatibility.
def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):
    print("Number of training samples:", len(X_train))
    print("Unlabeled samples in training set:", sum(1 for x in y_train if x == -1))
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(
        "Micro-averaged F1 score on test set: %0.3f"
#         % f1_score(y_test, y_pred, average="micro")
    )
    print("-" * 10)
    print()

# df_train = df_final[df_final.label >= 0]
# df_test = df_final[df_final.label < 0]

# X_train, X_test, y_train, y_test = train_test_split(df_train['content'], df_train['label'])

# df_train = df_final[df_final.label >= 0]
# df_test = df_final[df_final.label < 0]

# X_train, X_test, y_train, y_test = train_test_split(df_train['content'], df_train['label'])

# print("Supervised SGDClassifier on 20% of the training data:")
# eval_and_print_metrics(pipeline, X_train, y_train, X_test, y_test)

# # set the non-masked subset to be unlabeled
# print("SelfTrainingClassifier on 20% of the training data (rest is unlabeled):")
# eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)

# if "CI" not in os.environ:
#     # LabelSpreading takes too long to run in the online documentation
#     print("LabelSpreading on 20% of the data (rest is unlabeled):")
#     eval_and_print_metrics(ls_pipeline, X_train, y_train, X_test, y_test)

# model = st_pipeline.fit(X_train, y_train)

# y_pred = model.predict(df_test['content'])

# df_test['label'] = y_pred

df_test= pd.read_excel('labeled_data_from_model.xlsx')

df_new = df_labeled.append(df_test[['content', 'label']])
# print(df_new.head())

# print(df_new.tail())

X_train, X_test, y_train, y_test = train_test_split(df_new['content'], df_new['label'], test_size=0.2)

# Commented out IPython magic to ensure Python compatibility.
model = pipeline.fit(X_train, y_train)
y_pred = model.predict(X_test)
# print(
#     "Micro-averaged F1 score on test set: %0.3f"
#     % f1_score(y_test, y_pred, average="micro")
# )

score_train2 = pipeline.score(X_train, y_train)
score_test2 = pipeline.score(X_test, y_test)
abs_2 =abs(score_test2-score_train2)
entries2=[]
entries2.append(['Active Learning', score_train2, 
                    score_test2, abs_2])

cv_df2 = pd.DataFrame(entries2, 
                     columns=['model_name', 'score_train', 
                              'score_test', 'abs|score|'])


from sklearn.metrics import confusion_matrix, classification_report
conf_m2 = confusion_matrix(y_test, y_pred)
class_re2= classification_report(y_test, y_pred)

# """- precision, recall, f1-score của phương pháp áp dụng label bằng active learning đều cao hơn so với sử dụng label dựa vào rating => áp dụng model này để dự đoán các comment mới

# ##**6. PREDICT NEW COMMENTS**
# """

# text_new = ['Mặc xấu, vải kém chất lượng','Tạm được, không quá xấu', 'Giao hàng nhanh chóng, rất hài lòng']
# for text_1 in text_new:
#   text_2 = process_text(text_1 , emoji_dict, teen_dict, wrong_lst)
#   text_2 = covert_unicode(text_2)
#   text_2 = process_postag_thesea(text_2)
#   text_2 = remove_stopword(text_2, stopwords_lst)
#   yhat = model.predict([text_2])
#   if yhat==0:
#     label = "negative"
#   elif yhat==1:
#     label = "neutral"
#   else:
#     label = "positive"
#   print(text_1,"-", label)

## Hien thi ket qua tren streamlit
import streamlit as st

st.title('Data Science')
st.write('## Sentiment Analysis for E-Commer')
menu = ['Overview', 'Build Project','Active Learning', 'New Prediction']
choice = st.sidebar.selectbox('Menu',menu)
if choice =='Overview':
    st.subheader('Overview')
    st.write('''
    - Trong thương mại điện tử, việc liên tục nâng cao sản phẩm và dịch vụ để đáp ứng nhu cầu khách hàng nhằm nâng cao uy tính của doanh nghiệp là công việc hàng đầu của các doanh nghiệp tham gia sàn thương mại điện tử.
    - Hệ thống hỗ trợ doanh nghiệp phân loại các phản hồi của khách hàng thành 3 nhóm: tích cực, tiêu cực, trung tính dựa trên dữ liệu dạng văn bản. Hệ thống được xây dựng dựa trên lịch sử những đánh giá của các khách hàng đã có trước đó, dữ liệu được thu thập từ phần bình luận và đánh giá của khách hàng ở trang Shopee.vn nhánh ngành Thời trang.
    - Hệ thống giúp doanh nghiệp có thể biết được những phản hồi nhanh chóng của khách hàng về sản phẩm hay dịch vụ của họ, điều này giúp cho doanh nghiệp hiểu được tình hình kinh doanh, hiểu được ý kiến của khách hàng từ đó giúp doanh nghiệp cải thiện hơn trong dịch vụ, sản phẩm.
    ''')
elif choice=='Build Project':
    st.subheader('Build Project')
    st.write('#### Data Preprocessing')
    st.write('##### Show data:')
    st.table(data[['content','rating']].head())
    st.write('#### Build model and evaluation:')
    st.table(cv_df)
    st.write('#### Confution Matrix:')
    st.table(conf_m)
    st.text(class_re)
elif choice=='Active Learning':
    st.subheader('Active Learning')
    st.write('#### Data Preprocessing')
    st.write('##### Data labeled:')
    st.table(df_labeled.head())
    st.write('##### Data not labeled:')
    st.table(df_not_labeled.head())
    st.write('#### Build model and evaluation:')
    st.table(cv_df2)
    st.write('#### Confution Matrix:')
    st.table(conf_m2)
    st.text(class_re2)

elif choice =='New Prediction':
    st.subheader('make new Prediction')
    st.write('### Input data')
    text_1 = st.text_input('Your Comment')
    text_2 = process_text(text_1 , emoji_dict, teen_dict, wrong_lst)
    text_2 = covert_unicode(text_2)
    text_2 = process_postag_thesea(text_2)
    text_2 = remove_stopword(text_2, stopwords_lst)
    yhat = model.predict([text_2])
    if yhat==0:
        label = "Negative"
    elif yhat==1:
        label = "Neutral"
    else:
        label = "Positive"
    st.write("Your comment is", label)